{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad43fba9",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "a. Build a Convolutional Neural Network, like what we built in lectures (without skip connections), to classify the images across all 10 classes in CIFAR 10. You need to adjust the fully connected layer at the end properly with respect to the number of output classes. Train your network for 300 epochs. Report your training time, training loss, and evaluation accuracy after 300 epochs. Analyze your results in your report and compare them against a fully connected network (homework 2) on training time, achieved accuracy, and model size. Make sure to submit your code by providing the GitHub URL of your course repository for this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011bb690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "data_path = '../data-unversioned/p1ch7/'\n",
    "from torchvision import transforms\n",
    "\n",
    "device= (torch.device('cuda') if torch.cuda.is_available()\n",
    "         else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")\n",
    "\n",
    "# Preprocess images\n",
    "preprocess = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )])\n",
    "\n",
    "# Store validation and training data, preprocess data\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True, transform = preprocess)\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True, transform = preprocess)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=256, shuffle = True)\n",
    "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=256, shuffle = False)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size = 3, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(32, 16, kernel_size = 3, padding = 1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 16, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 16)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "24aed34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader, val_loader):\n",
    "# Iterates through each epoch\n",
    "    model.train()\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "\n",
    "    # Calculate training loss\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            train_loss = loss_fn(outputs, labels)\n",
    "    \n",
    "    # Zeros gradient for backpropagation and gradient calculation\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Calculate validation loss and accuracy\n",
    "        correct = 0\n",
    "        count = 0\n",
    "        \n",
    "    # Put model in eval mode\n",
    "        model.eval()\n",
    "        \n",
    "    # Disables gradients for validation\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "                batch_size = imgs.shape[0]\n",
    "                outputs = model(imgs)\n",
    "                _, label_p = torch.max(outputs, dim=1)\n",
    "                count += labels.shape[0]\n",
    "                correct += int((label_p == labels).sum())\n",
    "                val_loss = loss_fn(outputs, labels)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "        acc = correct/count\n",
    "        \n",
    "        if epoch == 1 or epoch % 20 == 0:\n",
    "            print('{} Epoch: {}, Training Loss: {}, Validation Loss {}, Accuracy {}'.format(\n",
    "                datetime.datetime.now(), epoch, float(train_loss), float(val_loss), acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9388375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-27 22:09:54.926980 Epoch: 1, Training Loss: 2.13584041595459, Validation Loss 2.1027963161468506, Accuracy 0.2252\n",
      "2022-03-27 22:13:09.765961 Epoch: 20, Training Loss: 1.3218696117401123, Validation Loss 1.157007098197937, Accuracy 0.5746\n",
      "2022-03-27 22:16:34.271728 Epoch: 40, Training Loss: 0.8693691492080688, Validation Loss 0.9199755787849426, Accuracy 0.6507\n",
      "2022-03-27 22:20:01.889661 Epoch: 60, Training Loss: 0.7215105891227722, Validation Loss 0.7573404312133789, Accuracy 0.6568\n",
      "2022-03-27 22:23:31.719490 Epoch: 80, Training Loss: 0.6601418256759644, Validation Loss 0.7964374423027039, Accuracy 0.6914\n",
      "2022-03-27 22:27:00.277229 Epoch: 100, Training Loss: 0.8483656048774719, Validation Loss 0.9034740924835205, Accuracy 0.6782\n",
      "2022-03-27 22:30:30.463864 Epoch: 120, Training Loss: 0.7288081049919128, Validation Loss 0.9072661995887756, Accuracy 0.6718\n",
      "2022-03-27 22:33:58.552701 Epoch: 140, Training Loss: 0.4333290159702301, Validation Loss 0.6648874282836914, Accuracy 0.6762\n",
      "2022-03-27 22:37:25.282373 Epoch: 160, Training Loss: 0.7127763032913208, Validation Loss 0.9766222238540649, Accuracy 0.6662\n",
      "2022-03-27 22:40:51.119280 Epoch: 180, Training Loss: 0.5707577466964722, Validation Loss 1.1346203088760376, Accuracy 0.6548\n",
      "2022-03-27 22:44:16.996221 Epoch: 200, Training Loss: 0.6188122034072876, Validation Loss 1.2224034070968628, Accuracy 0.6634\n",
      "2022-03-27 22:47:42.940721 Epoch: 220, Training Loss: 0.33941078186035156, Validation Loss 1.1204171180725098, Accuracy 0.6828\n",
      "2022-03-27 22:51:09.207997 Epoch: 240, Training Loss: 0.22925107181072235, Validation Loss 1.2450191974639893, Accuracy 0.6719\n",
      "2022-03-27 22:54:34.978847 Epoch: 260, Training Loss: 0.3657832145690918, Validation Loss 1.3822871446609497, Accuracy 0.6578\n",
      "2022-03-27 22:58:00.860792 Epoch: 280, Training Loss: 0.5012490749359131, Validation Loss 1.2734901905059814, Accuracy 0.6635\n",
      "2022-03-27 23:01:27.276695 Epoch: 300, Training Loss: 0.4465285837650299, Validation Loss 1.7050681114196777, Accuracy 0.6313\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "model = Net()\n",
    "model = model.to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "n_epochs = 300\n",
    "\n",
    "training_loop(n_epochs, optimizer, model, loss_fn, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c95be71",
   "metadata": {},
   "source": [
    "b. Extend your CNN by adding one more additional convolution layer followed by an activation function and pooling function. You also need to adjust your fully connected layer properly with respect to intermediate feature dimensions. Train your network for 300 epochs. Report your training time, loss, and evaluation accuracy after 300 epochs. Analyze your results in your report and compare your model size and accuracy over the baseline implementation in Problem1.a. Do you see any over-fitting? Make sure to submit your code by providing the GitHub URL of your course repository for this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e681dbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtendedNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size = 3, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(32, 16, kernel_size = 3, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(16, 8, kernel_size = 3, padding = 1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv3(out)), 2)\n",
    "        out = out.view(-1, 4 * 4 * 8)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f1092d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-29 03:09:31.192759 Epoch: 1, Training Loss: 2.2898147106170654, Validation Loss 2.2693073749542236, Accuracy 0.1128\n",
      "2022-03-29 03:12:50.209251 Epoch: 20, Training Loss: 1.4860203266143799, Validation Loss 1.5341228246688843, Accuracy 0.487\n",
      "2022-03-29 03:16:18.182437 Epoch: 40, Training Loss: 1.1962817907333374, Validation Loss 1.1573352813720703, Accuracy 0.5747\n",
      "2022-03-29 03:19:45.687222 Epoch: 60, Training Loss: 1.1376391649246216, Validation Loss 0.998846173286438, Accuracy 0.5996\n",
      "2022-03-29 03:23:13.445723 Epoch: 80, Training Loss: 0.9487059712409973, Validation Loss 1.010607123374939, Accuracy 0.6537\n",
      "2022-03-29 03:26:41.489972 Epoch: 100, Training Loss: 0.7791354060173035, Validation Loss 0.7740625739097595, Accuracy 0.6643\n",
      "2022-03-29 03:30:09.737894 Epoch: 120, Training Loss: 1.0598613023757935, Validation Loss 0.9514034390449524, Accuracy 0.6305\n",
      "2022-03-29 03:33:37.688061 Epoch: 140, Training Loss: 0.5545362234115601, Validation Loss 0.8162549734115601, Accuracy 0.6724\n",
      "2022-03-29 03:37:05.941489 Epoch: 160, Training Loss: 0.7148316502571106, Validation Loss 0.9016898274421692, Accuracy 0.6792\n",
      "2022-03-29 03:40:34.910031 Epoch: 180, Training Loss: 0.809613823890686, Validation Loss 0.7799226641654968, Accuracy 0.6927\n",
      "2022-03-29 03:44:04.590184 Epoch: 200, Training Loss: 0.6871265172958374, Validation Loss 0.7579048871994019, Accuracy 0.6868\n",
      "2022-03-29 03:47:29.968141 Epoch: 220, Training Loss: 0.8084527850151062, Validation Loss 0.5322404503822327, Accuracy 0.6833\n",
      "2022-03-29 03:50:55.109394 Epoch: 240, Training Loss: 0.716856837272644, Validation Loss 0.8246714472770691, Accuracy 0.6954\n",
      "2022-03-29 03:54:19.312342 Epoch: 260, Training Loss: 0.8667291402816772, Validation Loss 0.8360951542854309, Accuracy 0.6899\n",
      "2022-03-29 03:57:46.131036 Epoch: 280, Training Loss: 0.8715659379959106, Validation Loss 0.9813388586044312, Accuracy 0.6744\n",
      "2022-03-29 04:01:13.541239 Epoch: 300, Training Loss: 0.5788018107414246, Validation Loss 0.8102067708969116, Accuracy 0.7059\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "model = ExtendedNet()\n",
    "model = model.to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "n_epochs = 300\n",
    "\n",
    "training_loop(n_epochs, optimizer, model, loss_fn, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14144a6",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "a. Build a ResNet based Convolutional Neural Network, like what we built in lectures (with skip connections), to classify the images across all 10 classes in CIFAR 10. For this problem, let’s use 10 blocks for ResNet and call it ResNet-10. Use the similar dimensions and channels as we need in lectures. Train your network for 300 epochs. Report your training time, training loss, and evaluation accuracy after 300 epochs. Analyze your results in your report and compare them against problem 1.b on training time, achieved accuracy, and model size. Make sure to submit your code by providing the GitHub URL of your course repository for this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c253020",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3, padding=1, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = torch.relu(out)\n",
    "        return out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a441e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetDeep(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1, bias=True)\n",
    "        self.resblocks = nn.Sequential(\n",
    "            *(n_blocks * [ResBlock(n_chans = n_chans1)]))\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = self.resblocks(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "92663663",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-28 15:35:28.945839 Epoch: 1, Training Loss: 1.615199089050293, Validation Loss 1.5518635511398315, Accuracy 0.3366\n",
      "2022-03-28 15:38:57.893864 Epoch: 20, Training Loss: 0.9375320672988892, Validation Loss 0.8421367406845093, Accuracy 0.6235\n",
      "2022-03-28 15:42:37.121219 Epoch: 40, Training Loss: 0.7135523557662964, Validation Loss 0.8400793671607971, Accuracy 0.6313\n",
      "2022-03-28 15:46:16.574269 Epoch: 60, Training Loss: 0.9295684695243835, Validation Loss 1.0677989721298218, Accuracy 0.6021\n",
      "2022-03-28 15:49:57.666728 Epoch: 80, Training Loss: 0.49588432908058167, Validation Loss 0.5357984900474548, Accuracy 0.668\n",
      "2022-03-28 15:53:39.492817 Epoch: 100, Training Loss: 0.24813368916511536, Validation Loss 0.6217750906944275, Accuracy 0.6528\n",
      "2022-03-28 15:57:23.281091 Epoch: 120, Training Loss: 0.3643956780433655, Validation Loss 0.8442394137382507, Accuracy 0.5835\n",
      "2022-03-28 16:01:07.390141 Epoch: 140, Training Loss: 0.27094414830207825, Validation Loss 1.0709232091903687, Accuracy 0.6278\n",
      "2022-03-28 16:04:48.853419 Epoch: 160, Training Loss: 0.35402435064315796, Validation Loss 3.385282278060913, Accuracy 0.587\n",
      "2022-03-28 16:08:29.219753 Epoch: 180, Training Loss: 0.01844796910881996, Validation Loss 1.5809718370437622, Accuracy 0.6383\n",
      "2022-03-28 16:12:09.811782 Epoch: 200, Training Loss: 0.0034997337497770786, Validation Loss 3.033633232116699, Accuracy 0.6434\n",
      "2022-03-28 16:15:50.790643 Epoch: 220, Training Loss: 0.0017652945825830102, Validation Loss 3.5920846462249756, Accuracy 0.6436\n",
      "2022-03-28 16:19:31.335131 Epoch: 240, Training Loss: 0.0006278324872255325, Validation Loss 3.95495867729187, Accuracy 0.6426\n",
      "2022-03-28 16:23:13.905344 Epoch: 260, Training Loss: 0.00036146267666481435, Validation Loss 4.199808120727539, Accuracy 0.6437\n",
      "2022-03-28 16:26:57.359832 Epoch: 280, Training Loss: 0.0003347010933794081, Validation Loss 4.370786190032959, Accuracy 0.6432\n",
      "2022-03-28 16:30:39.269492 Epoch: 300, Training Loss: 0.00016735837562009692, Validation Loss 4.544049263000488, Accuracy 0.6436\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-3\n",
    "model = ResNetDeep()\n",
    "model = model.to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "n_epochs = 300\n",
    "\n",
    "training_loop(n_epochs, optimizer, model, loss_fn, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ee6a9d",
   "metadata": {},
   "source": [
    "b. Develop three additional trainings and evaluations for your ResNet-10 to assess the impacts of regularization to your \n",
    "ResNet-10.\n",
    "\n",
    "* Weight Decay with lambda of 0.001\n",
    "* Dropout with p=0.3\n",
    "* Batch Normalization\n",
    "Report and compare your training time, training loss, and evaluation accuracy after 300 epochs across these three different trainings. Analyze your results in your report and compare them against problem 1.a on training time, achieved accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d5396310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-28 16:31:35.808076 Epoch: 1, Training Loss: 2.0224757194519043, Validation Loss 1.8004446029663086, Accuracy 0.3647\n",
      "2022-03-28 16:35:05.663879 Epoch: 20, Training Loss: 0.8954801559448242, Validation Loss 1.1519253253936768, Accuracy 0.6329\n",
      "2022-03-28 16:38:46.288436 Epoch: 40, Training Loss: 0.45526495575904846, Validation Loss 1.5089259147644043, Accuracy 0.6546\n",
      "2022-03-28 16:42:27.231768 Epoch: 60, Training Loss: 0.7342430353164673, Validation Loss 2.1878068447113037, Accuracy 0.6545\n",
      "2022-03-28 16:46:11.121129 Epoch: 80, Training Loss: 0.40167880058288574, Validation Loss 2.6666769981384277, Accuracy 0.6238\n",
      "2022-03-28 16:49:58.183716 Epoch: 100, Training Loss: 0.5262927412986755, Validation Loss 2.8048529624938965, Accuracy 0.6004\n",
      "2022-03-28 16:55:17.400482 Epoch: 120, Training Loss: 0.2502633333206177, Validation Loss 2.8714916706085205, Accuracy 0.6299\n",
      "2022-03-28 17:01:46.102947 Epoch: 140, Training Loss: 0.26064467430114746, Validation Loss 5.066389083862305, Accuracy 0.566\n",
      "2022-03-28 17:07:59.375656 Epoch: 160, Training Loss: 0.18811720609664917, Validation Loss 3.725801706314087, Accuracy 0.6341\n",
      "2022-03-28 17:14:11.886210 Epoch: 180, Training Loss: 0.022031091153621674, Validation Loss 5.333888053894043, Accuracy 0.6346\n",
      "2022-03-28 17:20:34.899788 Epoch: 200, Training Loss: 0.0035990867763757706, Validation Loss 7.613266468048096, Accuracy 0.6372\n",
      "2022-03-28 17:25:13.822434 Epoch: 220, Training Loss: 0.0010901426430791616, Validation Loss 8.756011009216309, Accuracy 0.6361\n",
      "2022-03-28 17:29:53.701901 Epoch: 240, Training Loss: 0.0008027740987017751, Validation Loss 9.267526626586914, Accuracy 0.6387\n",
      "2022-03-28 17:34:50.465874 Epoch: 260, Training Loss: 0.0009071846725419164, Validation Loss 9.433282852172852, Accuracy 0.6386\n",
      "2022-03-28 17:40:25.516245 Epoch: 280, Training Loss: 0.001235382747836411, Validation Loss 9.409139633178711, Accuracy 0.6375\n",
      "2022-03-28 17:45:40.978283 Epoch: 300, Training Loss: 0.0007362619508057833, Validation Loss 9.460640907287598, Accuracy 0.6373\n"
     ]
    }
   ],
   "source": [
    "# 1. Weight Decay with lambda of 0.001\n",
    "learning_rate = 3e-3\n",
    "model = ResNetDeep()\n",
    "model = model.to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.001) # Using optimizer param for weight decay\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "n_epochs = 300\n",
    "\n",
    "training_loop(n_epochs, optimizer, model, loss_fn, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b0ac3436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Dropout with p=0.3\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(n_chans, n_chans, kernel_size=3, padding=1, bias=True)\n",
    "        self.conv1_dropout = nn.Dropout2d(p=0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv1_dropout(out)\n",
    "        out = torch.relu(out)\n",
    "        return out + x\n",
    "    \n",
    "class ResNetDeepDropout(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1, bias=True)  \n",
    "        self.conv1_dropout = nn.Dropout2d(p=0.3)\n",
    "        self.resblocks = nn.Sequential(\n",
    "            *(n_blocks * [ResBlock(n_chans = n_chans1)]))\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = self.conv1_dropout(out)\n",
    "        out = self.resblocks(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "74a4b8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-28 17:51:26.564704 Epoch: 1, Training Loss: 1.9746595621109009, Validation Loss 1.7630641460418701, Accuracy 0.2834\n",
      "2022-03-28 17:57:02.362717 Epoch: 20, Training Loss: 1.1441643238067627, Validation Loss 1.106041431427002, Accuracy 0.5453\n",
      "2022-03-28 18:01:44.017708 Epoch: 40, Training Loss: 0.9868510961532593, Validation Loss 1.0816453695297241, Accuracy 0.6042\n",
      "2022-03-28 18:06:39.639702 Epoch: 60, Training Loss: 0.9195165634155273, Validation Loss 1.195173978805542, Accuracy 0.6206\n",
      "2022-03-28 18:12:03.232226 Epoch: 80, Training Loss: 0.82476806640625, Validation Loss 1.0806975364685059, Accuracy 0.614\n",
      "2022-03-28 18:16:52.665402 Epoch: 100, Training Loss: 0.7496321201324463, Validation Loss 1.0769792795181274, Accuracy 0.6323\n",
      "2022-03-28 18:21:34.976960 Epoch: 120, Training Loss: 0.6145712733268738, Validation Loss 1.0937981605529785, Accuracy 0.6371\n",
      "2022-03-28 18:26:17.566755 Epoch: 140, Training Loss: 0.6057456731796265, Validation Loss 1.4627439975738525, Accuracy 0.6314\n",
      "2022-03-28 18:32:40.026357 Epoch: 160, Training Loss: 0.8371337056159973, Validation Loss 1.2032876014709473, Accuracy 0.6365\n",
      "2022-03-28 18:37:19.033575 Epoch: 180, Training Loss: 0.6060985922813416, Validation Loss 1.6643890142440796, Accuracy 0.6354\n",
      "2022-03-28 18:41:53.789639 Epoch: 200, Training Loss: 0.5333162546157837, Validation Loss 1.2710539102554321, Accuracy 0.6318\n",
      "2022-03-28 18:46:38.567818 Epoch: 220, Training Loss: 0.6615569591522217, Validation Loss 1.6898095607757568, Accuracy 0.6364\n",
      "2022-03-28 18:51:18.525850 Epoch: 240, Training Loss: 0.5773807764053345, Validation Loss 1.827298879623413, Accuracy 0.6274\n",
      "2022-03-28 18:55:51.280196 Epoch: 260, Training Loss: 0.5697849988937378, Validation Loss 1.3868721723556519, Accuracy 0.645\n",
      "2022-03-28 18:59:45.950320 Epoch: 280, Training Loss: 0.4563942551612854, Validation Loss 1.9509634971618652, Accuracy 0.6347\n",
      "2022-03-28 19:03:37.136951 Epoch: 300, Training Loss: 0.5658888220787048, Validation Loss 1.6822870969772339, Accuracy 0.6299\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-3\n",
    "model = ResNetDeepDropout()\n",
    "model = model.to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "n_epochs = 300\n",
    "\n",
    "training_loop(n_epochs, optimizer, model, loss_fn, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b50eec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Batch Normalization Report\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3,\n",
    "                             padding=1, bias=False)\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
    "        torch.nn.init.kaiming_normal_(self.conv.weight,\n",
    "                             nonlinearity='relu')\n",
    "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = torch.relu(out)\n",
    "        return out + x\n",
    "    \n",
    "class ResNetDeepBatchNorm(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1, bias=False)  # No bias needed as the Batch Norm handles it\n",
    "        self.resblocks = nn.Sequential(\n",
    "            *(n_blocks * [ResBlock(n_chans = n_chans1)]))\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = self.resblocks(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "45f3fdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-28 19:03:48.799472 Epoch: 1, Training Loss: 1.8426212072372437, Validation Loss 1.572396993637085, Accuracy 0.2984\n",
      "2022-03-28 19:07:28.082877 Epoch: 20, Training Loss: 1.0498212575912476, Validation Loss 1.106888771057129, Accuracy 0.6114\n",
      "2022-03-28 19:11:19.133890 Epoch: 40, Training Loss: 0.6952133178710938, Validation Loss 1.1077414751052856, Accuracy 0.6271\n",
      "2022-03-28 19:15:10.046787 Epoch: 60, Training Loss: 0.8130942583084106, Validation Loss 1.0169785022735596, Accuracy 0.6627\n",
      "2022-03-28 19:19:04.002297 Epoch: 80, Training Loss: 0.5004958510398865, Validation Loss 0.8437848091125488, Accuracy 0.6776\n",
      "2022-03-28 19:22:54.398751 Epoch: 100, Training Loss: 0.42693597078323364, Validation Loss 0.6154416799545288, Accuracy 0.6724\n",
      "2022-03-28 19:26:43.241867 Epoch: 120, Training Loss: 0.3638749420642853, Validation Loss 0.6699421405792236, Accuracy 0.657\n",
      "2022-03-28 19:30:29.536296 Epoch: 140, Training Loss: 0.3209161162376404, Validation Loss 0.7202544212341309, Accuracy 0.6622\n",
      "2022-03-28 19:34:16.950186 Epoch: 160, Training Loss: 0.4942391514778137, Validation Loss 1.118043065071106, Accuracy 0.6504\n",
      "2022-03-28 19:38:06.073043 Epoch: 180, Training Loss: 0.28886130452156067, Validation Loss 0.8488699197769165, Accuracy 0.65\n",
      "2022-03-28 19:41:54.944686 Epoch: 200, Training Loss: 0.1356380730867386, Validation Loss 0.8758068680763245, Accuracy 0.6476\n",
      "2022-03-28 19:45:44.261211 Epoch: 220, Training Loss: 0.1936902552843094, Validation Loss 1.3730833530426025, Accuracy 0.6273\n",
      "2022-03-28 19:49:31.360330 Epoch: 240, Training Loss: 0.1521233469247818, Validation Loss 2.2841601371765137, Accuracy 0.6418\n",
      "2022-03-28 19:53:25.600584 Epoch: 260, Training Loss: 0.13732275366783142, Validation Loss 2.2003910541534424, Accuracy 0.6345\n",
      "2022-03-28 19:57:17.301657 Epoch: 280, Training Loss: 0.03964248299598694, Validation Loss 2.0755221843719482, Accuracy 0.6457\n",
      "2022-03-28 20:01:08.614398 Epoch: 300, Training Loss: 0.15588948130607605, Validation Loss 1.7473150491714478, Accuracy 0.6122\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-3\n",
    "model = ResNetDeepBatchNorm()\n",
    "model = model.to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "n_epochs = 300\n",
    "\n",
    "training_loop(n_epochs, optimizer, model, loss_fn, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85d48bb",
   "metadata": {},
   "source": [
    "# Model Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "77f2179a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module Net is treated as a zero-op.\n",
      "Net(\n",
      "  0.039 M, 100.000% Params, 0.002 GMac, 100.000% MACs, \n",
      "  (conv1): Conv2d(0.001 M, 2.318% Params, 0.001 GMac, 42.987% MACs, 3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(0.005 M, 11.964% Params, 0.001 GMac, 55.461% MACs, 32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(0.033 M, 84.864% Params, 0.0 GMac, 1.537% MACs, in_features=1024, out_features=32, bias=True)\n",
      "  (fc2): Linear(0.0 M, 0.854% Params, 0.0 GMac, 0.015% MACs, in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "Computational complexity:       0.0 GMac\n",
      "Number of parameters:           38.65 k \n"
     ]
    }
   ],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "# Regular CNN Complexity\n",
    "macs, params = get_model_complexity_info(Net(), (3, 32, 32), as_strings=True,\n",
    "                                                   print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0fac32a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module ExtendedNet is treated as a zero-op.\n",
      "ExtendedNet(\n",
      "  0.011 M, 100.000% Params, 0.002 GMac, 100.000% MACs, \n",
      "  (conv1): Conv2d(0.001 M, 8.045% Params, 0.001 GMac, 42.088% MACs, 3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(0.005 M, 41.516% Params, 0.001 GMac, 54.302% MACs, 32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(0.001 M, 10.415% Params, 0.0 GMac, 3.406% MACs, 16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(0.004 M, 37.062% Params, 0.0 GMac, 0.189% MACs, in_features=128, out_features=32, bias=True)\n",
      "  (fc2): Linear(0.0 M, 2.963% Params, 0.0 GMac, 0.015% MACs, in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "Computational complexity:       0.0 GMac\n",
      "Number of parameters:           11.14 k \n"
     ]
    }
   ],
   "source": [
    "# Extended CNN Complexity    \n",
    "macs, params = get_model_complexity_info(ExtendedNet(), (3, 32, 32), as_strings=True,\n",
    "                                                   print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5228da06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module ResBlock is treated as a zero-op.\n",
      "Warning: module ResNetDeep is treated as a zero-op.\n",
      "ResNetDeep(\n",
      "  0.076 M, 100.000% Params, 0.025 GMac, 100.000% MACs, \n",
      "  (conv1): Conv2d(0.001 M, 1.136% Params, 0.001 GMac, 3.581% MACs, 3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (resblocks): Sequential(\n",
      "    0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "    (0): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (7): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (8): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (9): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (fc1): Linear(0.066 M, 86.226% Params, 0.0 GMac, 0.265% MACs, in_features=2048, out_features=32, bias=True)\n",
      "  (fc2): Linear(0.0 M, 0.434% Params, 0.0 GMac, 0.001% MACs, in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "Computational complexity:       0.02 GMac\n",
      "Number of parameters:           76.04 k \n"
     ]
    }
   ],
   "source": [
    "# ResNet based CNN Complexity    \n",
    "macs, params = get_model_complexity_info(ResNetDeep(), (3, 32, 32), as_strings=True,\n",
    "                                                   print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ebf87e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module ResBlock is treated as a zero-op.\n",
      "Warning: module ResNetDeep is treated as a zero-op.\n",
      "ResNetDeep(\n",
      "  0.076 M, 100.000% Params, 0.025 GMac, 100.000% MACs, \n",
      "  (conv1): Conv2d(0.001 M, 1.136% Params, 0.001 GMac, 3.581% MACs, 3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (resblocks): Sequential(\n",
      "    0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "    (0): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (7): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (8): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (9): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (fc1): Linear(0.066 M, 86.226% Params, 0.0 GMac, 0.265% MACs, in_features=2048, out_features=32, bias=True)\n",
      "  (fc2): Linear(0.0 M, 0.434% Params, 0.0 GMac, 0.001% MACs, in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "Computational complexity:       0.02 GMac\n",
      "Number of parameters:           76.04 k \n"
     ]
    }
   ],
   "source": [
    "# ResNet based CNN Complexity with weight decay regularization   \n",
    "macs, params = get_model_complexity_info(ResNetDeep(), (3, 32, 32), as_strings=True,\n",
    "                                                   print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "71544f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module Dropout2d is treated as a zero-op.\n",
      "Warning: module ResBlock is treated as a zero-op.\n",
      "Warning: module ResNetDeepDropout is treated as a zero-op.\n",
      "ResNetDeepDropout(\n",
      "  0.076 M, 100.000% Params, 0.025 GMac, 100.000% MACs, \n",
      "  (conv1): Conv2d(0.001 M, 1.178% Params, 0.001 GMac, 3.709% MACs, 3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv1_dropout): Dropout2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.3, inplace=False)\n",
      "  (resblocks): Sequential(\n",
      "    0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "    (0): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (7): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (8): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (9): ResBlock(\n",
      "      0.009 M, 12.199% Params, 0.024 GMac, 96.025% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.115% Params, 0.024 GMac, 95.363% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.662% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (fc1): Linear(0.066 M, 86.190% Params, 0.0 GMac, 0.265% MACs, in_features=2048, out_features=32, bias=True)\n",
      "  (fc2): Linear(0.0 M, 0.434% Params, 0.0 GMac, 0.001% MACs, in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "Computational complexity:       0.02 GMac\n",
      "Number of parameters:           76.07 k \n"
     ]
    }
   ],
   "source": [
    "# ResNet based CNN Complexity with dropout regularization  \n",
    "macs, params = get_model_complexity_info(ResNetDeepDropout(), (3, 32, 32), as_strings=True,\n",
    "                                                   print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ac90cafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module ResBlock is treated as a zero-op.\n",
      "Warning: module ResNetDeepBatchNorm is treated as a zero-op.\n",
      "ResNetDeepBatchNorm(\n",
      "  0.076 M, 100.000% Params, 0.025 GMac, 100.000% MACs, \n",
      "  (conv1): Conv2d(0.001 M, 1.136% Params, 0.001 GMac, 3.581% MACs, 3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (resblocks): Sequential(\n",
      "    0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "    (0): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (7): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (8): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (9): ResBlock(\n",
      "      0.009 M, 12.204% Params, 0.024 GMac, 96.152% MACs, \n",
      "      (conv): Conv2d(0.009 M, 12.120% Params, 0.024 GMac, 95.489% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (batch_norm): BatchNorm2d(0.0 M, 0.084% Params, 0.0 GMac, 0.663% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (fc1): Linear(0.066 M, 86.226% Params, 0.0 GMac, 0.265% MACs, in_features=2048, out_features=32, bias=True)\n",
      "  (fc2): Linear(0.0 M, 0.434% Params, 0.0 GMac, 0.001% MACs, in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "Computational complexity:       0.02 GMac\n",
      "Number of parameters:           76.04 k \n"
     ]
    }
   ],
   "source": [
    "# ResNet based CNN Complexity with batch norm regularization   \n",
    "macs, params = get_model_complexity_info(ResNetDeepBatchNorm(), (3, 32, 32), as_strings=True,\n",
    "                                                   print_per_layer_stat=True, verbose=True)\n",
    "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3319ab79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
